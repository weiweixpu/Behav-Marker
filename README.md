# ğŸ§  Behav-Marker: A Novel Artificial Intelligence based Detection Marker for Prodromal Parkinson's Disease Screening ğŸ”

This is the code implementation of the method used in our paper ğŸ“„ *"Behav-Marker: A Novel Artificial Intelligence based Detection Marker for Prodromal Parkinson's Disease Screening"*

## âš™ï¸ Requirements
Our models are trained and tested in the environment of Python 3.8, R 4.2.2, PyTorch 1.9.1, CUDA 11.1. ğŸ’» Our interactive software is suitable for win10 and above system versions.

## ğŸ“Š Datasets
The third-party datasets used in our study are provided under the Creative Commons Public License ğŸŒ:  
- [Movebank](https://www.movebank.org/)  
- [Microsoft T-Drive Project](https://www.microsoft.com/en-us/research/publication/t-drive-trajectory-data-sample/)  
- [Geolife Trajectories 1.3](https://www.microsoft.com/en-us/download/details.aspx?id=52367)  
- [Taxi GPS Dataset](https://tianchi.aliyun.com/dataset/94216)  
- [Gowalla Dataset](https://snap.stanford.edu/data/loc-gowalla.html).  

### ğŸ“‚ Data Structure
**Please Note:** ğŸ§ª This study uses the Reworded Open Field 63007 experimental device (RWD Life Science Co., Ltd., Shenzhen, China). If you are using a different device for data collection, please make sure to preprocess your data into the same style as used in this project (Including but not limited to the color, shape of the image). âš ï¸ Otherwise, the provided models may not work directly with your data â€” you may need to fine-tune or retrain the models to ensure compatibility. ğŸ”§ğŸ“Š

We make internal data public ğŸ“¢. The internal data (trajectory plots, heatmaps and motor behavior characteristics) used in this study and the open field test features (Total Movement Distance, Average Velocity, Line Crossing Frequency, Center Zones Entries, Center Zone Duration, Center Zone Path Length, Peripheral Zones Entries, Peripheral Zone Duration, Peripheral Zones Path Length) are now open to the research community through an open platformğŸ¤— ([PD-Movement-Behavior-Dataset](https://huggingface.co/datasets/WeiWei-XPU/PD-Movement-Behavior-Dataset)) ğŸ¤, which can be used by academic research peers to verify experimental results, promote method replication, and promote collaborative exploration in the field of early screening for Parkinson's disease.

Dataset with the following folder structure ğŸ“:
```
Dataset/
â”œâ”€â”€Characteristics of open field test/
â”‚   â”œâ”€â”€Control.csv
â”‚   â”œâ”€â”€Third.csv
â”‚   â”œâ”€â”€Sixth.csv
â”‚   â”œâ”€â”€Tenth.csv
â”œâ”€â”€ heat map/
â”‚   â”œâ”€â”€ Control/
â”‚   â”œâ”€â”€ Third/
â”‚   â”œâ”€â”€ Sixth/
â”‚   â””â”€â”€ Tenth/
â””â”€â”€ Trajectories/
    â”œâ”€â”€ Control/
    â”œâ”€â”€ Third/
    â”œâ”€â”€ Sixth/
    â””â”€â”€ Tenth/
 ```

## ğŸ› ï¸ Open-Source Parkinson's Disease Screening Tool (v1.0.0)
In order to automate the screening and analysis of prodromal behaviors of Parkinson's disease ğŸ¤–, we have developed an interactive software tool ğŸ–¥ï¸ (applicable to Windows 10 and above) that integrates the Parkinson's disease screening model. By simply uploading two types of data ğŸ“¤, trajectory map and heat map, the risk of Parkinson's disease can be quantitatively assessed. The interactive software is now open to the scientific research community through an open platform ğŸ”“, and can be used by academic and scientific research peers to verify the experimental results.

## ğŸ¤– Models
We also make public the best model parameters optimized on the internal dataset used in this study (.pth format) ğŸ§ , which can be obtained through the open platform:
- [ğŸ”— Multimodal-fusion-ViT-base-model](https://huggingface.co/WeiWei-XPU/Multimodal-fusion-ViT-base)
- [ğŸ”— Foundation-model-heatmap](https://huggingface.co/WeiWei-XPU/foundation-model-heatmap)
- [ğŸ”— Multimodal-fusion-densenet121-model](https://huggingface.co/WeiWei-XPU/Multimodal-fusion-densenet121-model)
- [ğŸ”— Multimodal-fusion-resnet50-model](https://huggingface.co/WeiWei-XPU/Multimodal-fusion-resnet50-model)
- [ğŸ”— Foundation-model-trajectory-plot](https://huggingface.co/WeiWei-XPU/foundation-model-trajectory-plot)
- [ğŸ”— Multimodal-fusion-foundation-model](https://huggingface.co/WeiWei-XPU/Multimodal-fusion-foundation-model)
- [ğŸ”— Multimodal-fusion-ViT-large-model](https://huggingface.co/WeiWei-XPU/Multimodal-fusion-ViT-large-model)
- [ğŸ”— Pretrained-densenet121-heatmap-model](https://huggingface.co/WeiWei-XPU/pretrained-densenet121-heatmap-model)
- [ğŸ”— Pretrained-densenet121-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/pretrained-densenet121-trajectory-plot-model)
- [ğŸ”— Pretrained-resnet50-heatmap-model](https://huggingface.co/WeiWei-XPU/pretrained-resnet50-heatmap-model)
- [ğŸ”— Pretrained-resnet50-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/pretrained-resnet50-trajectory-plot-model)
- [ğŸ”— Pretrained-ViT-base-heatmap-model](https://huggingface.co/WeiWei-XPU/pretrained-ViT-base-heatmap-model)
- [ğŸ”— Pretrained-ViT-base-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/pretrained-ViT-base-trajectory-plot-model)
- [ğŸ”— Pretrained-ViT-large-heatmap-model](https://huggingface.co/WeiWei-XPU/pretrained-ViT-large-heatmap-model)
- [ğŸ”— Pretrained-ViT-large-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/pretrained-ViT-large-trajectory-plot-model)
- [ğŸ”— Random-initial-densenet121-heatmap-model](https://huggingface.co/WeiWei-XPU/random-intial-densenet121-heatmap-model)
- [ğŸ”— Random-initial-densenet121-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/random-intial-densenet121-trajectory-plot-model)
- [ğŸ”— Random-initial-resnet50-heatmap-model](https://huggingface.co/WeiWei-XPU/random-intial-resnet50-heatmap-model)
- [ğŸ”— Random-initial-resnet50-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/random-intial-resnet50-trajectory-plot-model)
- [ğŸ”— Random-initial-ViT-base-heatmap-model](https://huggingface.co/WeiWei-XPU/random-intial-ViT-base-heatmap-model)
- [ğŸ”— Random-initial-ViT-base-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/random-intial-ViT-base-trajectory-plot-model)
- [ğŸ”— Random-initial-ViT-large-heatmap-model](https://huggingface.co/WeiWei-XPU/random-intial-ViT-large-heatmap-model)
- [ğŸ”— Random-initial-ViT-large-trajectory-plot-model](https://huggingface.co/WeiWei-XPU/random-intial-ViT-large-trajectory-plot-model).

## ğŸ› ï¸ Foundation models fine-tuning
```bash
conda create -n mae_finetune python=3.8
conda activate mae_finetune
```
```bash
pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 --extra-index-url https://download.pytorch.org/whl/cu117
pip install pandas scikit-learn matplotlib opencv-python
```
# ğŸ“‚Directory structure requirements
```
/data/zhenyuan/dataset
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class0/
â”‚   â””â”€â”€ class1/
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ class0/
â”‚   â””â”€â”€ class1/
â””â”€â”€ test/
    â”œâ”€â”€ class0/
    â””â”€â”€ class1/
```
```bash
# Pretraining weight path
pretrain_path = "/data/zhenyuan/pretrain/save_result/encoder_checkpoint.pth"
```
```bash
# Data path
train_dataset = '/data/zhenyuan/dataset/train'
val_dataset = '/data/zhenyuan/dataset/validation'
test_dataset = '/data/zhenyuan/dataset/test'
```
```bash
# Output path
save_path = "/data/zhenyuan/save_model(outputs)/foundation_model_HM.pth"
```
## ğŸ› ï¸Fine-tuning execution
```bash
# Basic training (single GPU)
python Heatmap_foundation_model_fine-tuning.py
```
```bash
# Multi-GPU training (2 GPUs)
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 Heatmap_foundation_model_fine-tuning.py
```
